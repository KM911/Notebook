---
file-created: 2023 11 21
last-modified: 2023 11 25
---

## 爬虫是什么?学完之后就会"吃国家饭"吗?

(本来是给同学入门用的 所以比较杂乱)

### 我们是如何上网的
假设你现在想要上B站看视频,可能是某个同学分享的视频链接. 假设这是[好兄弟分享的视频](https://www.bilibili.com/video/BV1JP41147xY/) `https://www.bilibili.com/video/BV1JP41147xY`

你的电脑上肯定没有这个视频,那你的浏览器是如何获取这个视频并播放的呢?
![[获取网络资源.canvas|获取网络资源]]


### 网络知识科普

我不想直接掏出计算机网络,然后大谈特谈OSI7层 TCP/IP4层网络模型,没有必要,了解一部分就好了. 

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%92%8C%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/7.jpg)


#### URL 
全称为 Uniform Resource Locators (统一资源定位符)就是我们常说的网址,光看名字我们就可以知道url就是给网络资源提供位置信息的,就像生活中的GPS吗?


#### IP
全称为 Internet Protocol (网络协议) 这个原文其实不好,没有体现出其作用.我个人喜欢称其为 Internet Position(网络位置),通过IP就可以知道对方在网络中的位置.

>[!info] 在cmd中输入 `ipconfig` 就可以看到你的IP地址.不过通常是内网IP,没有什么使用价值.

通过ssh连接服务器

#### DNS和域名
DNS全称为Domain Name System (域名解析系统),URL本身其实是无法确定"位置"的,真正确定位置的是IP,我们需要通过访问DNS将域名解析后才可以获得其服务器IP.

>[!info]  www.bilibili.com 就是B站的域名.其对应的IP可能有多个,借助[IP查询工具](https://ip.chinaz.com/www.bilibili.com)就可以看到其对应的IP了.
>
>
>可以直接通过IP访问服务器 [`http://81.68.91.70`](http://81.68.91.70) ,侧面证明了两点 1.URL本身其实是无法定位的 需要借助DNS解析获取域名对应的IP才可以访问服务器 2.IP才真正表示网络位置

#### HTTP 和 HTTPS
HTTP全称是 Hypertext Transfer Protocol (超文本传输协议) HTTP最大的特点就是明文传输,在网络链路上的任何一个节点理论上都可以看到你的内容,十分不安全,计算机科学家们自然会想设计一种更加安全的协议.我很难想象,在HTTPS出现之前,我们的数据都是明文在网络上传输的.

HTTPS = HTTP + TLS/SSL 可以简单理解为加密的HTTP,通常情况下我们是无法获取到HTTPS数据包里的内容的. 感兴趣的同学可以了解一下 中间人攻击 [MITM](https://zh.wikipedia.org/zh-hans/%E4%B8%AD%E9%97%B4%E4%BA%BA%E6%94%BB%E5%87%BB#:~:text=%E4%B8%AD%E9%97%B4%E4%BA%BA%E6%94%BB%E5%87%BB%EF%BC%88%E8%8B%B1%E8%AF%AD%EF%BC%9AMan%2D,%E8%A2%AB%E6%94%BB%E5%87%BB%E8%80%85%E5%AE%8C%E5%85%A8%E6%8E%A7%E5%88%B6%E3%80%82). 

##### URL链接的构成
scheme:scheme-specific-part
这里是因为还有好多协议比如 我们一般情况下(几乎是所有情况下)使用的都是HTTP或者HTTPS😅
scheme:IP or domain (default port):path 


#### HTTP 结构
上面都是十分抽象的概念,我们来看看一个HTTP请求到底长什么样.
对于一个HTTP请求通常结构为:
请求行（request line）、请求头部（header）、空行和请求数据(body)

````col
```col-md
flexGrow=1
===
POST /upload HTTP/1.1\r\n     
Host: www.example.com\r\n
Content-Type: application/octet-stream\r\n
Content-Length: 1024\r\n
Connection: keep-alive\r\n
\r\n
< request data>
```
```col-md
flexGrow=1
===
请求行  Method Path HPPT版本
{

请求头部 
header

}
空行 对应 \r\n
请求数据 

```

````
响应请求结构为:
状态行、header、空行和body。
````col
```col-md
flexGrow=1
===
HTTP/1.1 200 OK
Content-Type: application/octet-stream\r\n
Content-Length: 1024\r\n
Connection: keep-alive\r\n
\r\n
< respond data>
```
```col-md
flexGrow=1
===
状态行 http版本 状态码 状态码信息
{
header

}
空行 

body
```

````

#### HTTP Method

为了描述请求的行为,HTTP协议中指定了一些Method.
* GET 获取数据
* POST 提交数据
* DELETE 删除数据
* [MDN HTTP request methods](https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods)

不过具体的行为,还是取决于服务器如何处理.

#### 常见HTTP状态码

* 200 OK 表示成功 
* 301 Moved Permanently 永久重定向
* 404 NOT FOUND 资源不存在
* 502 Bad Gateway 网关错误
* [MDN HTTP response status codes](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status)


## 爬虫和服务器

我们已经知道了"上网"的本质就是发送请求和服务器响应请求.下面我们就来实现一个简单的Server 和 Client.

(任何编程语言只要实现了socket都可以编写server和CLient.
### 编写Server

下面是python编写的一个非常简单的Server.任何GET请求都会返回"hello world".[http://localhost:8080/](http://localhost:8080/)

```python
import web

urls = (
    '/(.*)', 'hello'
)
app = web.application(urls, globals())

class hello:
    def GET(self):
        return 'Hello, world!'
# 默认端口8080
if __name__ == "__main__":
    app.run()
```


### 编写Client
```python
import requests 
URL = "http://localhost:8080/"
res = requests.get(URL)
print(res.text)
```

### 交互式编程
这里的"交互式"是指,我们 Client 和 Server 功能是对应的.通常情况下,编写爬虫就是要明确Server的逻辑,然后针对性地进行操作.一个出题,一个解题.

所以说爬虫非常麻烦,不同的网站,可能有不同的逻辑和策略,你需要"量体裁衣".一套代码对应一个网站,有的时候甚至只能对应一个页面的解析.

由于服务端代码是人写的,于人斗总是非常复杂和麻烦.服务端可以采取一些"莫名奇妙"的策略.

### 给爬虫定性
如果从网络请求的角度来看,爬虫本身和浏览器以及各种APP的行为本身没有任何区别.都是域名解析然后访问服务器,都是发送HTTP请求.我们使用浏览器时,浏览器会发送各种请求并解析,使用QQ,抖音各种

问题来了,为什么我们经常会看见有的人因为爬虫"吃国家饭"呢?
* 无限制的多线程请求. 导致服务器负载过大,和恶行网络攻击没有什么区别.
* 违反了隐私协议. 比如爬取用户个人数据非法牟利
* 将数据用于商业行为. 爬取商业数据造成不正当竞争,爬取大量带有知识产权的数据用于商业目的

我们应该编写的爬虫
* 合理的请求频率 对于服务器友好.最好和正常用户的访问频率保持一致.(夜间可以适当提高请问频率 因为这个时候也没有正常用户 服务器压力相对比较小)
* 遵守 Robots 协议 (即使没有Robots协议 我们也应该知道什么是不可以的 毕竟RObots协议就是一个君子协定)
* 不要侵犯他人隐私 不要将数据用于商业目的 

不过说实话 大部分的网站都不欢迎爬虫 以B站为例 [Robots.txt](https://www.bilibili.com/robots.txt)

一句话概括就是: 除开搜索引擎的爬虫,其他任何crawl行为都是不被许可的.结束了,还学什么爬虫.

### 爬虫可以获取例如vip视频吗?

一言以蔽之 爬虫只能获取正常用户获取到的信息. 

你可以理解为vip视频是被存放到 **银行** , 没有权限的人是肯定无法从里面**取钱**的.

除非你说 你要去"抢银行". 

所以说下面这种视频 不用想都是"假的". 当然了,如果你有一个VIP账号的话,利用你的cookie确实可以起到下面的效果, 但是完全不是一回事了.

![image-20230727211004793](http://81.68.91.70/pg/image/KM27xQJSrnWH.webp)

![image-20230727211025874](http://81.68.91.70/pg/image/KMo3wqsrVTbO.webp)

### 放弃写爬虫的想法吧?

随着技术的发展,"动态网页"越来越多,内容展示和用户操作高度绑定,比如需要点击更多评论才会显示二级评论,不断下滑才会进行新的资源请求... 你获取到的只是一个"空壳",其他资源都是懒加载而不是直接内嵌在网站.

加上国内互联网越来越走向封闭,要么是不提供网页版,给APP引流,要么是只有登录用户才可以访问,没有开发的API接口...

你需要学会监听,抓包,分析js文件才可以获取到最终的数据,编写爬虫的难度也越来越大了. 

如果你想爬取视频资源,你可以需要知道视频分片,m3u8,ts,视频编解码,将flv格式转成mp4,通过xml或者txt文件添加字幕,视频和音频混合... 你需要有非常多的视频处理相关的知识,或者说你会使用ffmpeg

这些问题 我只能说 啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊

## 面向接口编程

就如我们上面说的一样,网站资源不再是内嵌到网页里了,当时肯定还是存在一个请求要说明资源信息的.我们的任务就变成了寻找对应的接口了.

以爬取LOL英雄的原画为例吧. [LOL攻略中心](https://101.qq.com/#/hero)
