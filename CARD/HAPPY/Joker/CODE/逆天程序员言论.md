## 既是嘲笑也是提醒自己

不得不承认,因为前十年中国互联网蓬勃发展,导致很多水平"底下"的人也成为了程序员,有的甚至是在一些大型公司担任"重要"职位. 每当我看见这些逆天言论时,我都会在像,把他们放到现在,还能成为程序员吗? 

当又一个十年过去了,我们是不是也会被新人看不起呢?  还是说可以凭借真实的经验,让新人感概前辈的洞悉与明察. 

[Stop learning frameworks – Eduards Sizovs](https://sizovs.net/frameworks/)
## 逆天言论 

* 百万级并发算什么,我都是上亿级并发的. 👍
![[Pasted image 20231104142058.webp]]
* 正常人发言
*![[Pasted image 20231104141758.webp]]


## 爬虫课程一些感想

首先我们需要承认,`scrapy`和 `seleium`框架都是非常常用并且值得学习的python爬虫框架,但是没有任何的基础知识真的可以解决问题吗? 

### 没有思考的行动等于白费力气 

有思考过为什么需要使用`seleium`吗? 

我的回答是, `seleium` 通过模拟浏览器行为,是最接近正常用户操作的,从服务端来看,根本就无法区分`seleium`和正常用户.它提供的诸如按键的点击事件,表单的提交等等是其他爬虫框架所不能提供的. 可以利用对DOM的控制实现用户登陆,破解验证等功能. 

当然了,静态的爬虫肯定还是可以实现上述功能的,无非是基于cookie的验证或者基于token的验证嘛,但是就是需要花费比较多的时间去理解其逻辑了. 

再来看看`scrapy` 框架給我们带来了什么? 莫名其妙的调度,每次,非常得让人难以理解. 

`高性能的异步操作` : 没有太大意义,爬虫的最关键问题其实不是性能而是反爬虫和数据处理. 
`可扩展性` : 确实scrapy提供了诸如`pipeline` , `middwaer` 来增强功能,但是我并不认为传统的爬虫框架不可以. 


### 我的选择

如果日后我需要写爬虫的话,我应该会使用如下的组合. 

无验证网页 : requests+ gevent + bs4 + sqlite
带验证网页 :  seleium + sqlite

我不将 静态网页和动态网页区分是因为, 
以vue项目为例,它的index.html文件就是几乎空的,所有内容都是依赖后续加载的js文件进行渲染的. 这样的网站我认为还是 "静态网站" 




